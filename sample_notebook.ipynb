{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from Code.Models.hybrid_recsys import *\n",
    "from Code.Models.nuemf_hybrid import *\n",
    "from Code.Models.content_based import ContentBasedRecommender\n",
    "from Code.Models.collaborative import CollaborativeFilteringRecommender\n",
    "from Code.utils.evaluation import * \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Set device to MPS if available.\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Load your data (adjust file paths as needed)\n",
    "movies_df = pd.read_csv(\"Data/movies.csv\", engine='python')\n",
    "ratings_df = pd.read_csv(\"Data/ratings.csv\", engine='python')\n",
    "\n",
    "# Preprocess movies: (Assume you already created genre_features and mapping below)\n",
    "movies_df['genre_list'] = movies_df['genres'].apply(lambda x: x.split('|') if isinstance(x, str) else [])\n",
    "unique_genres = sorted(list({genre for genres in movies_df['genre_list'] for genre in genres}))\n",
    "for genre in unique_genres:\n",
    "    movies_df[genre] = movies_df['genre_list'].apply(lambda x: int(genre in x))\n",
    "genre_features = movies_df[unique_genres].values\n",
    "\n",
    "\n",
    "train_df, test_df = train_test_split(ratings_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build a pivot table and compute user means.\n",
    "ratings_pivot = train_df.pivot_table(index='userId', columns='movieId', values='rating')\n",
    "user_means = ratings_pivot.mean(axis=1)\n",
    "\n",
    "# Create mapping dictionaries.\n",
    "user_ids_all = ratings_df['userId'].unique()\n",
    "movie_ids_all = ratings_df['movieId'].unique()\n",
    "user2index = {u: i for i, u in enumerate(sorted(user_ids_all))}\n",
    "movie2index = {m: i for i, m in enumerate(sorted(movie_ids_all))}\n",
    "\n",
    "# Create a dataset for your PyTorch models.\n",
    "class MovieLensDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, ratings_df, movies_df, user2index, movie2index, genre_features, user_means):\n",
    "        self.df = ratings_df.copy()\n",
    "        self.user2index = user2index\n",
    "        self.movie2index = movie2index\n",
    "        self.df['user_idx'] = self.df['userId'].apply(lambda x: self.user2index[x])\n",
    "        self.df['movie_idx'] = self.df['movieId'].apply(lambda x: self.movie2index[x])\n",
    "        self.df['rating_norm'] = self.df.apply(lambda row: row['rating'] - user_means.loc[row['userId']], axis=1)\n",
    "        movieid_to_index = {mid: idx for idx, mid in enumerate(movies_df['movieId'].values)}\n",
    "        self.df['genre_vector'] = self.df['movieId'].apply(lambda x: genre_features[movieid_to_index[x]])\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        return (torch.tensor(row['user_idx'], dtype=torch.long),\n",
    "                torch.tensor(row['movie_idx'], dtype=torch.long),\n",
    "                torch.tensor(row['rating_norm'], dtype=torch.float),\n",
    "                torch.tensor(row['genre_vector'], dtype=torch.float))\n",
    "\n",
    "hybrid_train_dataset = MovieLensDataset(train_df, movies_df, user2index, movie2index, genre_features, user_means)\n",
    "train_loader = DataLoader(hybrid_train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "\n",
    "hybrid_test_dataset = MovieLensDataset(test_df, movies_df, user2index, movie2index, genre_features, user_means)\n",
    "test_loader = DataLoader(hybrid_test_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Build dictionary for positive interactions (rating >= 4.0).\n",
    "def build_positive_user_items(ratings_df, user2index, movie2index, threshold=4.0):\n",
    "    pos_items = {}\n",
    "    for _, row in ratings_df.iterrows():\n",
    "        if row['rating'] >= threshold:\n",
    "            u = user2index[row['userId']]\n",
    "            m = movie2index[row['movieId']]\n",
    "            pos_items.setdefault(u, set()).add(m)\n",
    "    return pos_items\n",
    "\n",
    "positive_user_items = build_positive_user_items(train_df, user2index, movie2index, threshold=4.0)\n",
    "all_movie_indices = list(movie2index.values())\n",
    "# Inverse mapping from movie index to original movie ID.\n",
    "inv_movie2index = {v: k for k, v in movie2index.items()}\n",
    "# Mapping from movieId (original) to row index in movies_df.\n",
    "movieid_to_index = {mid: idx for idx, mid in enumerate(movies_df['movieId'].values)}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANDOM: Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Random Recommender Baseline:\n",
      "Avg Precision@10: 0.0012\n",
      "Avg Recall@10: 0.0013\n",
      "Avg NDCG@10: 0.0019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0012170385395537525, 0.001305731566045504, 0.0018739750936774763)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def random_recommender(user_id):\n",
    "    \"\"\"\n",
    "    Randomly recommends 10 movies that the user has not already rated in the training set.\n",
    "    \n",
    "    Args:\n",
    "        user_id: The original user ID.\n",
    "    \n",
    "    Returns:\n",
    "        A list of 10 movie IDs selected at random.\n",
    "    \"\"\"\n",
    "    # Get the set of movies that the user rated in the training data.\n",
    "    rated = set(train_df[train_df['userId'] == user_id]['movieId'])\n",
    "    \n",
    "    # Candidate movies are those not rated by the user.\n",
    "    candidate_movies = [movie for movie in movie2index.keys() if movie not in rated]\n",
    "    \n",
    "    # If there are fewer than k candidates, return them all.\n",
    "    if len(candidate_movies) < 10:\n",
    "        return candidate_movies\n",
    "    \n",
    "    # Randomly sample 10 movies from the candidates.\n",
    "    return random.sample(candidate_movies, 10)\n",
    "\n",
    "# Evaluate the random recommender baseline.\n",
    "print(\"\\nEvaluating Random Recommender Baseline:\")\n",
    "evaluate_recommender_metrics(random_recommender, \n",
    "                     user_ids=test_df['userId'].unique(), \n",
    "                     test_df=test_df, \n",
    "                     k=10, \n",
    "                     threshold=4.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content Based and Collaborative Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Content-Based Recommender:\n",
      "Avg Precision@10: 0.0088\n",
      "Avg Recall@10: 0.0080\n",
      "Avg NDCG@10: 0.0106\n",
      "\n",
      "Evaluating Collaborative Filtering Recommender:\n",
      "Avg Precision@10: 0.1645\n",
      "Avg Recall@10: 0.1580\n",
      "Avg NDCG@10: 0.2210\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.16448979591836738, 0.15795731340964334, 0.22102827093694025)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and fit the content-based recommender.\n",
    "cb_recommender = ContentBasedRecommender(movies_df, genre_features)\n",
    "cb_recommender.fit(train_df, threshold=4.0)\n",
    "\n",
    "# Initialize and fit the collaborative filtering recommender.\n",
    "cf_recommender = CollaborativeFilteringRecommender()\n",
    "cf_recommender.fit(train_df)\n",
    "\n",
    "# Wrap the recommend methods to match the evaluation function interface.\n",
    "def content_based_wrapper(user_id):\n",
    "    return cb_recommender.recommend(user_id, k=10)\n",
    "\n",
    "def collaborative_wrapper(user_id):\n",
    "    return cf_recommender.recommend(user_id, k=10)\n",
    "\n",
    "print(\"Evaluating Content-Based Recommender:\")\n",
    "evaluate_recommender_metrics(content_based_wrapper, user_ids=test_df['userId'].unique(), test_df=test_df, k=10, threshold=4.0)\n",
    "\n",
    "print(\"\\nEvaluating Collaborative Filtering Recommender:\")\n",
    "evaluate_recommender_metrics(collaborative_wrapper, user_ids=test_df['userId'].unique(), test_df=test_df, k=10, threshold=4.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIGHTFM Recommender (Library model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/MLL/lib/python3.9/site-packages/lightfm/_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from lightfm import LightFM\n",
    "from lightfm.data import Dataset as LFMDataset\n",
    "from lightfm.cross_validation import random_train_test_split\n",
    "from lightfm.evaluation import precision_at_k, recall_at_k, auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LightFM Evaluation Results:\n",
      "Precision@10: 0.0816\n",
      "Recall@10: 0.0687\n",
      "NDCG@10: 0.0677\n"
     ]
    }
   ],
   "source": [
    "# Normalize ratings for LightFM (shift normalized ratings to be nonnegative)\n",
    "ratings_pivot = train_df.pivot_table(index='userId', columns='movieId', values='rating').fillna(0)\n",
    "shift = abs(ratings_pivot.min().min())\n",
    "normalized_ratings = ratings_pivot.copy() + shift\n",
    "\n",
    "# Create and fit the LightFM dataset using training data only.\n",
    "lfm_dataset = LFMDataset()\n",
    "lfm_dataset.fit(\n",
    "    users=train_df['userId'].unique(),\n",
    "    items=train_df['movieId'].unique(),\n",
    "    item_features=unique_genres\n",
    ")\n",
    "\n",
    "# Build interaction data \n",
    "def build_interactions(df, normalized_ratings):\n",
    "    interactions = []\n",
    "    for _, row in df.iterrows():\n",
    "        user_id = row['userId']\n",
    "        movie_id = row['movieId']\n",
    "        weight = (\n",
    "            normalized_ratings.loc[user_id, movie_id] \n",
    "            if (movie_id in normalized_ratings.columns) \n",
    "            else 0\n",
    "        )\n",
    "        interactions.append((user_id, movie_id, weight))\n",
    "    return interactions\n",
    "\n",
    "train_interactions_data = build_interactions(train_df, normalized_ratings)\n",
    "test_interactions_data = build_interactions(test_df, normalized_ratings)\n",
    "\n",
    "train_interactions, _ = lfm_dataset.build_interactions(train_interactions_data)\n",
    "lfm_train, lfm_val = random_train_test_split(train_interactions, test_percentage=0.2)\n",
    "\n",
    "# Filter out movies not in training set from the movies DataFrame\n",
    "valid_movie_ids = set(train_df['movieId'].unique())\n",
    "movies_df_filtered = movies_df[movies_df['movieId'].isin(valid_movie_ids)]\n",
    "\n",
    "# features matrix\n",
    "lfm_item_features = lfm_dataset.build_item_features(\n",
    "    [(row['movieId'], row['genre_list']) for _, row in movies_df_filtered.iterrows()]\n",
    ")\n",
    "\n",
    "# filter out items not in training for the test interactions\n",
    "test_interactions_data_filtered = [\n",
    "    (u, i, w) for (u, i, w) in test_interactions_data \n",
    "    if i in valid_movie_ids\n",
    "]\n",
    "test_interactions, _ = lfm_dataset.build_interactions(test_interactions_data_filtered)\n",
    "\n",
    "\n",
    "# train the LightFM model.\n",
    "lightfm_model = LightFM(loss='warp', no_components=50)\n",
    "lightfm_model.fit(lfm_train, item_features=lfm_item_features, epochs=30, num_threads=4)\n",
    "\n",
    "# Evaluate \n",
    "\n",
    "precision = precision_at_k(lightfm_model, lfm_val, item_features=lfm_item_features, k=10).mean()\n",
    "recall = recall_at_k(lightfm_model, lfm_val, item_features=lfm_item_features, k=10).mean()\n",
    "auc = auc_score(lightfm_model, lfm_val, item_features=lfm_item_features).mean()\n",
    "\n",
    "print(\"\\nLightFM Evaluation Results:\")\n",
    "print(f\"Precision@10: {precision:.4f}\")\n",
    "print(f\"Recall@10: {recall:.4f}\")\n",
    "\n",
    "def compute_ndcg_at_k(model, interactions, k=10):\n",
    "    n_users, n_items = interactions.shape\n",
    "    ndcg_scores = []\n",
    "    for user_id in range(n_users):\n",
    "        true_items = interactions.tocsr()[user_id].indices\n",
    "        if len(true_items) == 0:\n",
    "            continue\n",
    "        scores = model.predict(user_id, np.arange(n_items))\n",
    "        ranked_items = np.argsort(-scores)[:k]\n",
    "        dcg = sum([1.0 / np.log2(i + 2) for i, item in enumerate(ranked_items) if item in true_items])\n",
    "        ideal_hits = min(len(true_items), k)\n",
    "        idcg = sum([1.0 / np.log2(i + 2) for i in range(ideal_hits)])\n",
    "        ndcg_scores.append(dcg / idcg if idcg > 0 else 0.0)\n",
    "    return np.mean(ndcg_scores) if ndcg_scores else 0.0\n",
    "\n",
    "ndcg_10 = compute_ndcg_at_k(lightfm_model, lfm_val, k=10)\n",
    "print(f\"NDCG@10: {ndcg_10:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HYBRID RECOMMENDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HybridRecSys BPR Epoch 1/10: Loss 0.5508\n",
      "HybridRecSys BPR Epoch 2/10: Loss 0.4028\n",
      "HybridRecSys BPR Epoch 3/10: Loss 0.3516\n",
      "HybridRecSys BPR Epoch 4/10: Loss 0.3191\n",
      "HybridRecSys BPR Epoch 5/10: Loss 0.3025\n",
      "HybridRecSys BPR Epoch 6/10: Loss 0.2868\n",
      "HybridRecSys BPR Epoch 7/10: Loss 0.2759\n",
      "HybridRecSys BPR Epoch 8/10: Loss 0.2679\n",
      "HybridRecSys BPR Epoch 9/10: Loss 0.2597\n",
      "HybridRecSys BPR Epoch 10/10: Loss 0.2527\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the HybridRecSys model.\n",
    "num_users = len(user2index)\n",
    "num_movies = len(movie2index)\n",
    "num_genres = genre_features.shape[1]\n",
    "embedding_dim = 50\n",
    "\n",
    "hybrid_model = HybridRecSys(num_users, num_movies, num_genres, embedding_dim)\n",
    "\n",
    "# Set up optimizer.\n",
    "optimizer_hybrid_bpr = optim.Adam(hybrid_model.parameters(), lr=0.001)\n",
    "num_epochs_bpr = 10\n",
    "\n",
    "# Train using BPR loss.\n",
    "hybrid_model = hybrid_model.fit_bpr(train_loader, positive_user_items, all_movie_indices,\n",
    "                                    inv_movie2index, movieid_to_index, optimizer_hybrid_bpr,\n",
    "                                    num_epochs_bpr, device, genre_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@10: 0.1325\n",
      "Recall@10: 0.8380\n",
      "NDCG@10: 0.0116\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.13248027851651406, 0.8379853, 0.011636990117509407)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_hybrid_ranking(hybrid_model, test_loader, 10, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NeuMF model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuMFHybrid BPR Epoch 1/10: Loss 0.5467\n",
      "NeuMFHybrid BPR Epoch 2/10: Loss 0.4043\n",
      "NeuMFHybrid BPR Epoch 3/10: Loss 0.3494\n",
      "NeuMFHybrid BPR Epoch 4/10: Loss 0.3208\n",
      "NeuMFHybrid BPR Epoch 5/10: Loss 0.2994\n",
      "NeuMFHybrid BPR Epoch 6/10: Loss 0.2840\n",
      "NeuMFHybrid BPR Epoch 7/10: Loss 0.2719\n",
      "NeuMFHybrid BPR Epoch 8/10: Loss 0.2618\n",
      "NeuMFHybrid BPR Epoch 9/10: Loss 0.2535\n",
      "NeuMFHybrid BPR Epoch 10/10: Loss 0.2431\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the NeuMFHybrid model.\n",
    "num_users = len(user2index)\n",
    "num_movies = len(movie2index)\n",
    "num_genres = genre_features.shape[1]\n",
    "embedding_dim = 50\n",
    "neumf_model = NeuMFHybrid(num_users, num_movies, num_genres, embedding_dim)\n",
    "optimizer_neumf_bpr = optim.Adam(neumf_model.parameters(), lr=0.001)\n",
    "num_epochs_bpr = 10\n",
    "\n",
    "# Train using BPR loss.\n",
    "neumf_model = neumf_model.fit_bpr(train_loader, positive_user_items, all_movie_indices,\n",
    "                                   inv_movie2index, movieid_to_index, optimizer_neumf_bpr,\n",
    "                                   num_epochs_bpr, device, genre_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@10: 0.1198\n",
      "Recall@10: 0.6661\n",
      "NDCG@10: 0.0108\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.11977400690403216, 0.666134, 0.0108409449004788)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "evaluate_ranking_neumf(neumf_model, test_loader, 10, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
