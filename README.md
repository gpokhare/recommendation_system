# Recommendation System Project

This repository implements and evaluates multiple recommendation system approaches on the MovieLens dataset. The project includes a random baseline, straightforward content-based and collaborative filtering models, a LightFM model, and two hybrid neural models: HybridRecSys and NeuMFHybrid. The evaluation is performed using ranking metrics such as Precision@10, Recall@10, and NDCG@10.


## Introduction

In this project, we explore several recommendation approaches on the MovieLens dataset. We begin with a simple random baseline, then implement content-based filtering and collaborative filtering methods. We also evaluate the performance of the LightFM library as a strong baseline. Additionally, we propose two hybrid neural models—HybridRecSys and NeuMFHybrid—that integrate collaborative and content-based signals. The main objective is to compare these methods using ranking metrics such as Precision@10, Recall@10, and NDCG@10.

## Method

The methods evaluated in this study are:

- **Random Baseline:**  
  Randomly selects 10 movies that the user has not rated. This serves as a naive lower bound for performance.

- **Content-Based Filtering:**  
  Constructs a user profile based on the genres of movies the user rated positively. Recommendations are generated by ranking movies according to cosine similarity between the user profile and each movie’s genre vector.

- **Collaborative Filtering:**  
  Builds a user–item rating matrix and computes user–user cosine similarity. Recommendations are generated by aggregating ratings from similar users using a weighted average.

- **LightFM Model:**  
  Uses the LightFM library with a ranking loss (WARP) to combine collaborative and content-based signals. This model serves as an additional baseline.

- **HybridRecSys:**  
  A neural hybrid model that integrates user and movie embeddings with content features (genre vectors). The model can be trained using MSE loss for regression or Bayesian Personalized Ranking (BPR) loss for optimizing rankings.  
  *Note: In our experiments, HybridRecSys was trained for 10 epochs using BPR loss without extensive hyperparameter tuning.*

- **NeuMFHybrid:**  
  A neural model that fuses a Generalized Matrix Factorization (GMF) branch with a Multi-Layer Perceptron (MLP) branch, integrating both collaborative and content-based features.  
  *Note: NeuMFHybrid was also trained for 10 epochs using BPR loss without hyperparameter tuning.*

## Results

The evaluation metrics for each method are summarized in Table 1 below:

| **Model**                         | **Precision@10** | **Recall@10** | **NDCG@10** |
|-----------------------------------|------------------|---------------|-------------|
| Random Baseline                   | 0.0012           | 0.0013        | 0.0019      |
| Content-Based Filtering           | 0.0088           | 0.0080        | 0.0106      |
| Collaborative Filtering           | 0.1645           | 0.1580        | 0.2210      |
| LightFM                           | 0.0816           | 0.0687        | 0.0677      |
| HybridRecSys (BPR, 10 epochs)      | 0.1325           | 0.8380        | 0.0116      |
| NeuMFHybrid (BPR, 10 epochs)        | 0.1198           | 0.6661        | 0.0108      |

*Note: The hybrid models were trained for only 10 epochs due to limited time, and no grid search or hyperparameter tuning was performed.*

## Discussion

The results indicate that:

- The **Random Baseline** performs very poorly, as expected.
- **Content-Based Filtering** yields only marginal improvements over the random baseline.
- **Collaborative Filtering** achieves significantly higher Precision and NDCG, demonstrating the effectiveness of leveraging user–item interactions.
- The **LightFM** model, which combines collaborative and content signals, shows moderate performance.
- Both hybrid neural models (HybridRecSys and NeuMFHybrid) exhibit high recall but low NDCG scores, indicating that while many relevant items are retrieved, they are not well-ranked at the top.

These findings suggest that there is significant potential for improvement in the hybrid models through additional training epochs and thorough hyperparameter tuning. A grid search over parameters such as embedding dimensions, learning rates, and loss configurations may yield better ranking performance.

## Future Work

Future improvements include:
- Conducting a comprehensive grid search for hyperparameter tuning.
- Training the hybrid models for additional epochs.
- Incorporating additional content features (e.g., tags or movie descriptions).
- Exploring alternative architectures and loss functions.
